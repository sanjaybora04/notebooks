{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjaybora04/notebooks/blob/main/uptrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1uupJdIEhqQ"
      },
      "source": [
        "<h1 style=\"text-align: center;\">Retraining a Binary Classification Model by Identifying Data Drifts</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tqgBLcYEhqV"
      },
      "source": [
        "In this example, we consider a binary classification task of human orientation while exercising. That is, given the location of 17 key-points of the body such as the nose, shoulders, wrist, hips, ankles, etc., the model tries to predict whether the person is in a horizontal (see image 1 below) or a vertical (see image 2 below) position. \n",
        "\n",
        "Input: 34-dimensional vector that contains the x and y positions of the 17 key-points.\\\n",
        "Output: Orientation (horizontal - class 0 or vertical - class 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BkeVkh9Ehqb"
      },
      "source": [
        "![Horizontal_class.png](attachment:020c13d9-0eab-4a18-9d3a-fd645826319f.png)\n",
        "![Vertical_class.png](attachment:5d35fb64-5f4b-4426-8756-2016a5ddc9a8.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAn1AMvKEhqe"
      },
      "source": [
        "In this notebook, we will see how we can use UpTrain package to identify data drift and identify out of distribution cases on real-world data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "203u4c3YEhqg"
      },
      "source": [
        "### Install the required packages for this example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DarMFDlqEhqi",
        "outputId": "b9215dea-2b1b-4cad-8ac7-b02c41e688b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug) (7.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug) (2.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.7.3)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.8/dist-packages (from imgaug) (0.18.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug) (4.6.0.66)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (2023.1.23.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting uptrain\n",
            "  Downloading uptrain-0.0.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from uptrain) (1.10.4)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from uptrain) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from uptrain) (1.0.2)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from uptrain) (5.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->uptrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->uptrain) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->uptrain) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->uptrain) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->uptrain) (8.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic>=1.9.0->uptrain) (4.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->uptrain) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->uptrain) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.2->uptrain) (1.2.0)\n",
            "Installing collected packages: uptrain\n",
            "Successfully installed uptrain-0.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torch imgaug\n",
        "!pip install uptrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/uptrain-ai/uptrain.git\n",
        "!mv uptrain/examples/1_orientation_classification/helper_files helper_files\n",
        "!rm -rf uptrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBWdBw1fGpfL",
        "outputId": "aa6a7e0e-41a7-4159-8799-392d32bb89d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'uptrain'...\n",
            "remote: Enumerating objects: 1405, done.\u001b[K\n",
            "remote: Counting objects: 100% (544/544), done.\u001b[K\n",
            "remote: Compressing objects: 100% (306/306), done.\u001b[K\n",
            "remote: Total 1405 (delta 345), reused 350 (delta 233), pack-reused 861\u001b[K\n",
            "Receiving objects: 100% (1405/1405), 2.68 MiB | 4.34 MiB/s, done.\n",
            "Resolving deltas: 100% (779/779), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jeXe8ZGTEhqm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import uptrain\n",
        "\n",
        "from helper_files import read_json, KpsDataset\n",
        "from helper_files import body_length_signal, plot_all_cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvjduGm8Ehqq"
      },
      "source": [
        "Let's first download the example dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MLhVviBEhqw",
        "outputId": "a64da755-e3e7-40d7-e9c5-136b163861ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to download example dataset...\n",
            "Successfully installed wget\n",
            "Data downloaded\n",
            "Prepared Example Dataset\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"data\"\n",
        "remote_url = \"https://oodles-dev-training-data.s3.amazonaws.com/data.zip\"\n",
        "orig_training_file = 'data/training_data.json'\n",
        "if not os.path.exists(data_dir):\n",
        "    print(\"Starting to download example dataset...\")\n",
        "    try:\n",
        "        # Most Linux distributions have Wget installed by default.\n",
        "        # Below command is to install wget for MacOS\n",
        "        wget_installed_ok = subprocess.call(\"brew install wget\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "        print(\"Successfully installed wget\")\n",
        "    except:\n",
        "        dummy = 1\n",
        "    try:\n",
        "        if not os.path.exists(\"data.zip\"):\n",
        "            file_downloaded_ok = subprocess.call(\"wget \" + remote_url, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "            print(\"Data downloaded\")\n",
        "        with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"./\")\n",
        "        print(\"Prepared Example Dataset\")\n",
        "        os.remove(\"data.zip\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Could not load training data\")\n",
        "        print(\"Please follow following steps to manually download data\")\n",
        "        print(\"Step 1: Paste the link https://oodles-dev-training-data.s3.amazonaws.com/data.zip in your browser\")\n",
        "        print(\"Step 2: Once the zip file is downloaded, unzip it here (i.e. YOUR_LOC/uptrain/examples/1_orientation_classification/\")\n",
        "else:\n",
        "    print(\"Example dataset already present\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "32bSMNSVEhq2"
      },
      "source": [
        "#### Type of data files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USaHrERiEhq5"
      },
      "source": [
        "Let's define the training and testing datasets, and visualise some of the training samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "q5ZugR0REhq7",
        "outputId": "2f3dc91b-942c-43d3-a24c-a91de97d1708"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id  gt      Nose_X      Nose_Y  Left_Eye_X  Left_Eye_Y  \\\n",
              "0  12002202098   1  536.832198  175.195562  275.183835  299.200492   \n",
              "1  11004300163   1  127.299427  213.304615  120.006179  213.098156   \n",
              "2  18100208242   0  342.735809   75.173884  347.639763   69.066162   \n",
              "3  18100204340   0  335.262419  161.525842  340.358734  155.666068   \n",
              "4  12100104261   0  255.488160   62.442478  256.765451   58.603055   \n",
              "\n",
              "   Right_Eye_X  Right_Eye_Y  Left_Ear_X  Left_Ear_Y  ...  Right_Hip_X  \\\n",
              "0   321.438219    53.586762  438.831630  196.469141  ...   355.320493   \n",
              "1   119.749502   220.877945  123.240242  213.496218  ...   282.739062   \n",
              "2   337.646757    69.463328  354.332650   70.183796  ...   327.693125   \n",
              "3   329.570863   154.843509  347.034712  154.827196  ...   316.727216   \n",
              "4   251.489867    58.323107  255.327531   55.634296  ...   235.763698   \n",
              "\n",
              "   Right_Hip_Y  Left_Knee_X  Left_Knee_Y  Right_Knee_X  Right_Knee_Y  \\\n",
              "0   352.771307   282.603256   245.372110    -71.727270    148.854694   \n",
              "1   217.173672   331.887746   122.399542    369.934428    153.331971   \n",
              "2   175.678139   373.687116   236.403840    330.044019    238.719585   \n",
              "3   218.696415   375.741803   250.993843    285.306140    252.504808   \n",
              "4   136.902009   277.832912   177.679435    229.566259    191.052507   \n",
              "\n",
              "   Left_Ankle_X  Left_Ankle_Y  Right_Ankle_X  Right_Ankle_Y  \n",
              "0    377.204408    118.812093     368.630415      32.683708  \n",
              "1    407.764187     54.115847     373.738996     228.353284  \n",
              "2    383.867725    289.895923     335.013380     292.018822  \n",
              "3    384.364024    298.382275     275.523553     298.044853  \n",
              "4    284.397434    213.477405     224.158806     239.154790  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b143241-a8da-4b69-800e-5db4fae2d51a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gt</th>\n",
              "      <th>Nose_X</th>\n",
              "      <th>Nose_Y</th>\n",
              "      <th>Left_Eye_X</th>\n",
              "      <th>Left_Eye_Y</th>\n",
              "      <th>Right_Eye_X</th>\n",
              "      <th>Right_Eye_Y</th>\n",
              "      <th>Left_Ear_X</th>\n",
              "      <th>Left_Ear_Y</th>\n",
              "      <th>...</th>\n",
              "      <th>Right_Hip_X</th>\n",
              "      <th>Right_Hip_Y</th>\n",
              "      <th>Left_Knee_X</th>\n",
              "      <th>Left_Knee_Y</th>\n",
              "      <th>Right_Knee_X</th>\n",
              "      <th>Right_Knee_Y</th>\n",
              "      <th>Left_Ankle_X</th>\n",
              "      <th>Left_Ankle_Y</th>\n",
              "      <th>Right_Ankle_X</th>\n",
              "      <th>Right_Ankle_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12002202098</td>\n",
              "      <td>1</td>\n",
              "      <td>536.832198</td>\n",
              "      <td>175.195562</td>\n",
              "      <td>275.183835</td>\n",
              "      <td>299.200492</td>\n",
              "      <td>321.438219</td>\n",
              "      <td>53.586762</td>\n",
              "      <td>438.831630</td>\n",
              "      <td>196.469141</td>\n",
              "      <td>...</td>\n",
              "      <td>355.320493</td>\n",
              "      <td>352.771307</td>\n",
              "      <td>282.603256</td>\n",
              "      <td>245.372110</td>\n",
              "      <td>-71.727270</td>\n",
              "      <td>148.854694</td>\n",
              "      <td>377.204408</td>\n",
              "      <td>118.812093</td>\n",
              "      <td>368.630415</td>\n",
              "      <td>32.683708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11004300163</td>\n",
              "      <td>1</td>\n",
              "      <td>127.299427</td>\n",
              "      <td>213.304615</td>\n",
              "      <td>120.006179</td>\n",
              "      <td>213.098156</td>\n",
              "      <td>119.749502</td>\n",
              "      <td>220.877945</td>\n",
              "      <td>123.240242</td>\n",
              "      <td>213.496218</td>\n",
              "      <td>...</td>\n",
              "      <td>282.739062</td>\n",
              "      <td>217.173672</td>\n",
              "      <td>331.887746</td>\n",
              "      <td>122.399542</td>\n",
              "      <td>369.934428</td>\n",
              "      <td>153.331971</td>\n",
              "      <td>407.764187</td>\n",
              "      <td>54.115847</td>\n",
              "      <td>373.738996</td>\n",
              "      <td>228.353284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18100208242</td>\n",
              "      <td>0</td>\n",
              "      <td>342.735809</td>\n",
              "      <td>75.173884</td>\n",
              "      <td>347.639763</td>\n",
              "      <td>69.066162</td>\n",
              "      <td>337.646757</td>\n",
              "      <td>69.463328</td>\n",
              "      <td>354.332650</td>\n",
              "      <td>70.183796</td>\n",
              "      <td>...</td>\n",
              "      <td>327.693125</td>\n",
              "      <td>175.678139</td>\n",
              "      <td>373.687116</td>\n",
              "      <td>236.403840</td>\n",
              "      <td>330.044019</td>\n",
              "      <td>238.719585</td>\n",
              "      <td>383.867725</td>\n",
              "      <td>289.895923</td>\n",
              "      <td>335.013380</td>\n",
              "      <td>292.018822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18100204340</td>\n",
              "      <td>0</td>\n",
              "      <td>335.262419</td>\n",
              "      <td>161.525842</td>\n",
              "      <td>340.358734</td>\n",
              "      <td>155.666068</td>\n",
              "      <td>329.570863</td>\n",
              "      <td>154.843509</td>\n",
              "      <td>347.034712</td>\n",
              "      <td>154.827196</td>\n",
              "      <td>...</td>\n",
              "      <td>316.727216</td>\n",
              "      <td>218.696415</td>\n",
              "      <td>375.741803</td>\n",
              "      <td>250.993843</td>\n",
              "      <td>285.306140</td>\n",
              "      <td>252.504808</td>\n",
              "      <td>384.364024</td>\n",
              "      <td>298.382275</td>\n",
              "      <td>275.523553</td>\n",
              "      <td>298.044853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12100104261</td>\n",
              "      <td>0</td>\n",
              "      <td>255.488160</td>\n",
              "      <td>62.442478</td>\n",
              "      <td>256.765451</td>\n",
              "      <td>58.603055</td>\n",
              "      <td>251.489867</td>\n",
              "      <td>58.323107</td>\n",
              "      <td>255.327531</td>\n",
              "      <td>55.634296</td>\n",
              "      <td>...</td>\n",
              "      <td>235.763698</td>\n",
              "      <td>136.902009</td>\n",
              "      <td>277.832912</td>\n",
              "      <td>177.679435</td>\n",
              "      <td>229.566259</td>\n",
              "      <td>191.052507</td>\n",
              "      <td>284.397434</td>\n",
              "      <td>213.477405</td>\n",
              "      <td>224.158806</td>\n",
              "      <td>239.154790</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b143241-a8da-4b69-800e-5db4fae2d51a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b143241-a8da-4b69-800e-5db4fae2d51a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b143241-a8da-4b69-800e-5db4fae2d51a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Training data\n",
        "training_file = 'data/training_data.json'\n",
        "\n",
        "# A testing dataset to evaluate model performance\n",
        "golden_testing_file = 'data/golden_testing_data.json'\n",
        "\n",
        "# The data-points which the models sees in production\n",
        "real_world_test_cases = 'data/real_world_testing_data.json'\n",
        "\n",
        "# To annotate the collected data points, we extract the ground truth from a master annotation file \n",
        "# (we can also import from any other annotation pipelines such as an annotation job on Mechanical turk).\n",
        "annotation_args = {'master_file': 'data/master_annotation_data.json'}\n",
        "\n",
        "# Let's visualize some of the training examples\n",
        "training_data = read_json(training_file, dataframe=True)\n",
        "training_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w8udThgEhq_"
      },
      "source": [
        "![2.jpg](attachment:27ccdf5e-4706-4ee9-bcce-c7a0c262f488.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6zFIaP3EhrB"
      },
      "source": [
        "### Step 1: Train our Neural Network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55oKirpzEhrC"
      },
      "source": [
        "We have defined a simple Neural Net comprised of a fully-connected layer with relu activation followed by a fully-connected layer to transfer latent features into model outputs. We compute Binary Entropy loss and are using Adam optimiser to train the model\n",
        "\n",
        "![model.png](attachment:4d0b8efb-e059-4dad-8939-300423c98847.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34oVANZEEhrE",
        "outputId": "63eddbe4-a14f-4931-b30b-ad0625395cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on:  data/training_data.json  which has  1000  data-points\n",
            "Epoch 0: Loss 6.108189918821858\n",
            "Epoch 1: Loss 1.5432152893753806\n",
            "Epoch 2: Loss 0.9718629997024114\n",
            "Epoch 3: Loss 0.7866231806232639\n",
            "Epoch 4: Loss 0.56751997365115\n",
            "Epoch 5: Loss 0.5176478891863001\n",
            "Epoch 6: Loss 0.38865605023235894\n",
            "Epoch 7: Loss 0.4058310522496875\n",
            "Epoch 8: Loss 0.2512015529776268\n",
            "Epoch 9: Loss 0.3784227873119747\n",
            "Model saved at:  trained_models_torch/version_0\n"
          ]
        }
      ],
      "source": [
        "from helper_files import get_accuracy_torch, train_model_torch, BinaryClassification\n",
        "train_model_torch(training_file, 'version_0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfMlC9ZiEhrF"
      },
      "source": [
        "Next, let's see how our model performs on the golden testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjplKppOEhrH",
        "outputId": "5e615ce9-f370-483a-bb22-2d387a0782af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model: version_0  on  15731  data-points\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9289937066937893"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "get_accuracy_torch(golden_testing_file, 'version_0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zkhxncyEhrJ"
      },
      "source": [
        "Great, we have successfully trained our Neural Network which is giving more than 90% accuracy. We will now how we can use UpTrain package to identify data distribution shifts, collect edge cases and retrain the model to improve its accuracy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teQY8d4MEhrL"
      },
      "source": [
        "### Step 2: Define the list of checks to perform on model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV6rWfFAEhrM"
      },
      "source": [
        "In this example, we define a simple data drift check to identify any distribution shift between real-world test set and the reference dataset (the training dataset in this case). To achieve this, we set 'kps' (Keypoints) as the input variable, the framework performs clustering on the training dataset and checks if the real-world test set is following the similar distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwSHvm3aEhrO",
        "outputId": "8ec6be03-359c-43a8-87f4-0507856103a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Drift checks:  [{'type': <Anomaly.DATA_DRIFT: 'data_drift'>, 'reference_dataset': 'data/training_data.json', 'is_embedding': True, 'measurable_args': {'type': <MeasurableType.INPUT_FEATURE: 'input_feature'>, 'feature_name': 'kps'}}]\n"
          ]
        }
      ],
      "source": [
        "checks = [{\n",
        "        'type': uptrain.Anomaly.DATA_DRIFT,\n",
        "        'reference_dataset': orig_training_file,\n",
        "        'is_embedding': True,\n",
        "        \"measurable_args\": {\n",
        "            'type': uptrain.MeasurableType.INPUT_FEATURE,\n",
        "            'feature_name': 'kps'   # keypoints\n",
        "        },\n",
        "    }]\n",
        "\n",
        "print(\"Data Drift checks: \", checks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkLdEQHvEhrP"
      },
      "source": [
        "### Step 3: Define the training and evaluation arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGkSYjJwEhrR"
      },
      "source": [
        "We now attach the model training and evaluation pipelines so that UpTrain framework can automatically retrain the model in case it sees that the model is facing significant data drift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQrte0OuEhrS",
        "outputId": "25a9cd15-545f-4294-a7ce-53d046a93487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Pipelines:  {'annotation_method': {'method': <AnnotationMethod.MASTER_FILE: 1>, 'args': {'master_file': 'data/master_annotation_data.json'}}, 'training_func': <function train_model_torch at 0x7f49551069d0>, 'orig_training_file': 'data/training_data.json'} \n",
            "\n",
            "Evaluation Pipelines:  {'inference_func': <function get_accuracy_torch at 0x7f49551065e0>, 'golden_testing_dataset': 'data/golden_testing_data.json'}\n"
          ]
        }
      ],
      "source": [
        "# Define the training pipeline to annotate collected edge cases and retrain the model automatically\n",
        "training_args = {\n",
        "    \"annotation_method\": {\"method\": uptrain.AnnotationMethod.MASTER_FILE, \"args\": annotation_args}, \n",
        "    \"training_func\": train_model_torch, \n",
        "    \"orig_training_file\": orig_training_file,\n",
        "}\n",
        "\n",
        "# Define evaluation pipeline to test retrained model against original model\n",
        "evaluation_args = {\n",
        "    \"inference_func\": get_accuracy_torch,\n",
        "    \"golden_testing_dataset\": golden_testing_file,\n",
        "}\n",
        "\n",
        "print(\"Training Pipelines: \", training_args, \"\\n\")\n",
        "print(\"Evaluation Pipelines: \", evaluation_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI4930D0EhrT"
      },
      "source": [
        "### Step 4: Initialize the UpTrain Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF4-78ReEhrU",
        "outputId": "bd881c59-5973-47c1-ba19-f27075e7b1ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully Initialized UpTrain Framework\n"
          ]
        }
      ],
      "source": [
        "cfg = {\n",
        "    \"checks\": checks, \n",
        "    \"training_args\": training_args,\n",
        "    \"evaluation_args\": evaluation_args,\n",
        "\n",
        "    # Retrain when 200 datapoints are collected in the retraining dataset\n",
        "    \"retrain_after\": 200,\n",
        "    \n",
        "    # A local folder to store the retraining dataset\n",
        "    \"retraining_folder\": \"uptrain_smart_data\",\n",
        "    \n",
        "    # A function to visualize clusters in the data\n",
        "    \"cluster_visualize_func\": plot_all_cluster,\n",
        "}\n",
        "\n",
        "# Initialize the UpTrain framework object with config \n",
        "framework = uptrain.Framework(cfg)\n",
        "print(\"Successfully Initialized UpTrain Framework\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meV_qs0EEhrX"
      },
      "source": [
        "### Step 5: Deploy the model in production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH3yRmIsEhrY"
      },
      "source": [
        "Ship the model to production worry-free because the UpTrain tool will identify any data drifts, collect interesting data points and automatically retrain the model on them. To mimic deployment behavior, we are running the model on a 'real-world test set' and logging model inputs with UpTrain framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWuuWgavEhrZ",
        "outputId": "86d19049-ea64-4fab-d163-9926f9ea91cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50  edge cases identified out of  13424  total samples\n",
            "101  edge cases identified out of  15792  total samples\n",
            "150  edge cases identified out of  24128  total samples\n",
            "200  edge cases identified out of  26608  total samples\n",
            "\n",
            "Kicking off re-training\n",
            "Creating retraining dataset: uptrain_smart_data/1/training_dataset.json  by merging  data/training_data.json  and collected edge cases.\n",
            "\n",
            "Training on:  uptrain_smart_data/1/training_dataset.json  which has  2005  data-points\n",
            "Epoch 0: Loss 6.547668820619583\n",
            "Epoch 1: Loss 2.09667319195981\n",
            "Epoch 2: Loss 0.9921911590879351\n",
            "Epoch 3: Loss 0.5552357899793435\n",
            "Epoch 4: Loss 0.3871322651299773\n",
            "Epoch 5: Loss 0.28291736927766714\n",
            "Epoch 6: Loss 0.22658223121639368\n",
            "Epoch 7: Loss 0.1783210203748492\n",
            "Epoch 8: Loss 0.11531238443450138\n",
            "Epoch 9: Loss 0.13162718854009495\n",
            "Model saved at:  trained_models_torch/version_1\n",
            "Model retraining done...\n",
            "\n",
            "Generating comparison report...\n",
            "Evaluating model: version_0  on  15731  data-points\n",
            "Evaluating model: version_1  on  15731  data-points\n",
            "---------------------------------------------\n",
            "---------------------------------------------\n",
            "Old model accuracy:  0.9289937066937893\n",
            "Retrained model accuracy (ie 201 smartly collected data-points added):  0.9838535376009154\n",
            "---------------------------------------------\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "inference_batch_size = 16\n",
        "model_dir = 'trained_models_torch/'\n",
        "model_save_name = 'version_0'\n",
        "real_world_dataset = KpsDataset(\n",
        "    real_world_test_cases, batch_size=inference_batch_size, is_test=True\n",
        ")\n",
        "model = BinaryClassification()\n",
        "model.load_state_dict(torch.load(model_dir + model_save_name))\n",
        "model.eval()\n",
        "\n",
        "for i,elem in enumerate(real_world_dataset):\n",
        "\n",
        "    # Do model prediction\n",
        "    inputs = {\"data\": {\"kps\": elem[0][\"kps\"]}, \"id\": elem[0][\"id\"]}\n",
        "    x_test = torch.tensor(inputs[\"data\"][\"kps\"]).type(torch.float)\n",
        "    test_logits = model(x_test).squeeze() \n",
        "    preds = torch.round(torch.sigmoid(test_logits)).detach().numpy()\n",
        "\n",
        "    # Log model inputs and outputs to the uptrain Framework to monitor data drift\n",
        "    idens = framework.log(inputs=inputs, outputs=preds)\n",
        "\n",
        "    # Retrain only once\n",
        "    if framework.version > 1:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6fVasTBEhrb"
      },
      "source": [
        "#### Hurray! Our model after retraining performs significantly better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x963E1dkEhrd"
      },
      "source": [
        "Let's try to understand how UpTrain helped to improve our classification model.\n",
        "\n",
        "#### Training data clusters\n",
        "While initializing the UpTrain framework, it clusters the reference dataset (i.e. training dataset in our case). We are plotting the centroids and support (ie number of data-points belonging to that cluster) of all the 20 clusters in our training dataset.\n",
        "\n",
        "![training_dataset_clusters.png](attachment:56779bcd-7f8b-4e7a-8af3-c87a83bb0883.png)\n",
        "\n",
        "#### Edge cases clusters\n",
        "As we see, the UpTrain framework identifies out-of-distribution data-points and collects the edge-cases which are sparsely present in the training dataset.\n",
        "\n",
        "![collected_edge_cases_clusters.png](attachment:5a57b1ed-6cff-4482-a60a-b04bba3c40a5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni2OaRoiEhre"
      },
      "source": [
        "From the above plot generated while monitoring the model in production, we see that data drift occurs for many cases when the person is in a horizontal position. Specifically, cases when the person is in push-ups position are very sparse in our training dataset, causing the model predictions to go wrong for them. In the example of edge-case detection, we will see that how we can use this insight to define a \"Pushup\" signal, collect all push-up related data-points and specifically retrain on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPjaFhtOEhrf"
      },
      "source": [
        "## Do more with UpTrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWa22BVpEhrg"
      },
      "source": [
        "Apart from data drift, UpTrain has many other features such as \n",
        "1. Checking for edge-cases and collecting them for automated retraining\n",
        "2. Verifying data integrity, \n",
        "3. Monitoring model performance and accuracy of predictions, etc. \n",
        "\n",
        "To dig deeper into it, we recommend you checkout the other examples in the folder \"deepdive_examples\"."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}